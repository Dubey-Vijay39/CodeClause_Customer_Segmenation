{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMksvIj+VAbRi442pXjuW9j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dubey-Vijay39/CodeClause_Customer_Segmenation/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJWUdLouXYBs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_bjp = pd.read_csv(\"BJP.csv\", encoding=\"ISO-8859-1\")\n",
        "\n",
        "\n",
        "def returneditedBJP (x):\n",
        "  comment = x.lower()\n",
        "  if( (' rahul ' not in comment and 'rahul ' not in comment) and ' congress ' not in comment and ' cong ' not in comment):\n",
        "    comment = ' BJP ' + comment\n",
        "  elif ('rahul' in comment or ' rahul' in comment or 'rahul ' in comment):\n",
        "    comment = comment.replace('rahul', ' CONGRESS RAHUL ' )\n",
        "\n",
        "  return comment\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_bjp['commentText'] =  df_bjp['commentText'].apply(lambda x : returneditedBJP(x))\n",
        "\n",
        "\n",
        "#df_bjp['commentText'] =  df_bjp['commentText'].apply(lambda x : ' BJP ' + x if 'Rahul'  not in x.split())\n",
        "\n",
        "\n",
        "def returnedited (x):\n",
        "  comment = x.lower()\n",
        "  if( (' modi ' not in comment or 'modi ' not in comment) and ' bjp ' not in comment):\n",
        "    comment = ' CONGRESS ' + comment\n",
        "\n",
        "  elif ( 'modi '  in comment or  ' modi' in comment) :\n",
        "    comment = comment.replace('modi ', ' BJP MODI ' )\n",
        "\n",
        "  return comment\n",
        "\n",
        "df_congress = pd.read_csv(\"congress.csv\", encoding=\"ISO-8859-1\")\n",
        "df_congress['ï»¿commentText'] =  df_congress['ï»¿commentText'].apply(lambda x : returnedited(x))\n",
        "df_congress.rename(columns = {'ï»¿commentText': 'commentText'},inplace = True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#creating new column newlabel\n",
        "df_congress[\"newLabel\"] = 0\n",
        "\n",
        "df_congress.columns\n",
        "df_bjp.head()\n",
        "#df_bjp= df_congress\n",
        "#df_bjp.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s1-ER-8DXfDt",
        "outputId": "e6e2653d-fde2-410d-c700-84ee0ae2ada9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       commentText  Label\n",
              "0                     BJP banda apna 100 % best he      1\n",
              "1   BJP we need the king maker  ---- narendra modi      1\n",
              "2               BJP awesome... banda apna best hai      1\n",
              "3                                 BJP best pm ever      1\n",
              "4             CONGRESS RAHUL  gandhi left the chat      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-36a7223a-27a0-435a-a4be-fd0be0bf1558\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>commentText</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BJP banda apna 100 % best he</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BJP we need the king maker  ---- narendra modi</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BJP awesome... banda apna best hai</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BJP best pm ever</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CONGRESS RAHUL  gandhi left the chat</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36a7223a-27a0-435a-a4be-fd0be0bf1558')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-36a7223a-27a0-435a-a4be-fd0be0bf1558 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-36a7223a-27a0-435a-a4be-fd0be0bf1558');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c26b818a-908f-4053-b85e-e1444d6cee93\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c26b818a-908f-4053-b85e-e1444d6cee93')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c26b818a-908f-4053-b85e-e1444d6cee93 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Assigning 1 where comments are in favour of BJP and 0 where in favour of congress in comments of congress related xls file.\n",
        "df_congress.newLabel[df_congress.Label == 0] =1\n",
        "df_congress.newLabel[df_congress.Label == 1] =0\n",
        "#dropping column label\n",
        "df_congress.drop(columns=\"Label\", inplace= True)\n",
        "#renaming column newlabel to label\n",
        "df_congress.rename(columns={\"newLabel\":\"Label\"} , inplace= True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXhoZEi-YApu",
        "outputId": "1f13c5a9-a5ed-4df1-b7d2-f02d27992d8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-cb57243aed9c>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_congress.newLabel[df_congress.Label == 0] =1\n",
            "<ipython-input-3-cb57243aed9c>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_congress.newLabel[df_congress.Label == 1] =0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_bjp.shape)\n",
        "print(df_congress.shape)\n",
        "#merging dataframes of bjp and congress\n",
        "df_bjp = pd.concat([df_bjp, df_congress])\n",
        "\n",
        "print(df_bjp.shape)\n",
        "df_bjp.columns\n",
        "df_bjp.reset_index(inplace= True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oD17GE3tYDiV",
        "outputId": "3f773af0-515f-4c5c-b894-f14ceae710ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1952, 2)\n",
            "(1998, 2)\n",
            "(3950, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from sklearn.feature_extraction import text\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "punc = ['.', ',', '\"', \"'\", '?','??', '!', ':', ';', '(', ')', '[', ']', '{', '}',\"%\",'???']\n",
        "hingstops= ['kaun', 'kyun', 'im', 'm', 'i', 'se', 'u', 'esi', 'ho', 'is', 'aap', 'ab', 'actually', 'alreadi', 'always', 'amaz', 'ap', 'apna', 'apne', 'apni', 'aur', 'b', 'j', 'b', 'j', 'p',\n",
        "             'banda', 'aa', 'aab', 'aadmi', 'aam', 'ad' ,'agar' ,'aisa', 'aise', 'aisi', 'ak', 'bar', 'aur', 'away', 'b', 'baad', 'd', 'abhi', 'baat', 'hai'\n",
        "             'h', 'ko', 'ku', 'vs', 'boy', 'bro', 'brothers', 'sisters' ,'sister', 'brother', 'bt', 'c', 'chal', 'chale', 'cm', 'com', 'yaar',\n",
        "             'bhar', 'bhi', 'itni', 'bhot', 'bhut', 'bilkul', 'till', 'tha' ,'h', 'ye' ,'y', 'yuhi', 'yun', 'to', 'e', 'ki', 'ad', 'd', 'g', 'tha', 'modi','rahul','2019']\n",
        "stop_words= punc\n",
        "\n",
        "len(stop_words)\n",
        "#stop_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkIW69H3YGUO",
        "outputId": "ecf51a19-e865-4fca-fc01-44d87d4de094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "tokenizer = RegexpTokenizer(r'[a-zA-Z\\']+')\n",
        "\n",
        "\n",
        "\n",
        "def tokenize(text):\n",
        "  wordlist= []\n",
        "  for word in tokenizer.tokenize(text.lower()):\n",
        "    wordlist.append(word)\n",
        "  return wordlist\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tneUCEyqYK7J",
        "outputId": "4ca6e4ea-c627-45bc-e74e-aba4cf361d39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-preprocessing --user"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMpjRUrqdjjg",
        "outputId": "6186db4e-338d-4f12-e577-8f4825ede294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-preprocessing in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-preprocessing) (1.26.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras-preprocessing) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import time\n",
        "from keras import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "max_fatures = 1000 #or vocab size\n",
        "#Keras tokenizer\n",
        "tokenizer = Tokenizer(nb_words=max_fatures, split=' ', )\n",
        "tokenizer.fit_on_texts(df_bjp.commentText.values)\n",
        "X1 = tokenizer.texts_to_sequences(df_bjp.commentText.values)\n",
        "X1 = sequence.pad_sequences(X1, maxlen= max_fatures)\n",
        "\n",
        "Y1 = (df_bjp.Label).values #pd.get_dummies\n",
        "\n",
        "#Train test split\n",
        "X1_train, X1_test, Y1_train, Y1_test = train_test_split(X1,Y1, random_state = 42)\n",
        "print(X1_train.shape,Y1_train.shape)\n",
        "print(X1_test.shape,Y1_test.shape)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7T-_BUJPYOOt",
        "outputId": "2d2a71c3-db9e-41f7-9112-2b225e22e0cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/text.py:98: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2962, 1000) (2962,)\n",
            "(988, 1000) (988,)\n",
            "Found 5824 unique tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(stop_words = stop_words, tokenizer = tokenize, max_features = 500, ngram_range=(1,3), lowercase= True)\n",
        "tfdf = vectorizer.fit_transform(df_bjp.commentText)\n",
        "words = vectorizer.get_feature_names()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "ZEFItMaJYUFJ",
        "outputId": "060b4b5c-3248-4dfd-ea0d-ab34deed7c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Tokenizer' object has no attribute 'tokenize'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-939a78c43899>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlowercase\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtfdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_bjp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommentText\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2131\u001b[0m             \u001b[0msublinear_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublinear_tf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m         )\n\u001b[0;32m-> 2133\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1386\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-6dec27d25652>\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mwordlist\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mwordlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwordlist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Tokenizer' object has no attribute 'tokenize'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation ##80 acc batch 100 , epoch 50\n",
        "# embed_dim = 150\n",
        "# lstm_out = 500\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(max_fatures, embed_dim,input_length = X1.shape[1], dropout=0.2))\n",
        "# model.add(Conv1D(150, 5, activation='relu')) # 128 * 128 5 FILTERS i/p - 10 filters +1 = 491\n",
        "# model.add(MaxPooling1D(pool_size=3)) # 4 LAYERS OF POOLING\n",
        "# model.add(LSTM(64, dropout_U=0.2,dropout_W=0.2, return_sequences = False))\n",
        "# #model.add(LSTM(50, dropout_U=0.2,dropout_W=0.2, return_sequences = False))\n",
        "# model.add(Dense(1,activation='sigmoid'))\n",
        "# model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "# print(model.summary())\n",
        "\n",
        "# from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation 80.76 2249 sec,  1.13  acctrain -98.73\n",
        "# embed_dim = 150\n",
        "# lstm_out = 500\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(max_fatures, embed_dim,input_length = X1.shape[1], dropout=0.1))\n",
        "# model.add(Conv1D(64, 5, activation='relu')) # 128 * 128 5 FILTERS i/p - 10 filters +1 = 491\n",
        "# model.add(MaxPooling1D(pool_size=3)) # 4 LAYERS OF POOLING\n",
        "# model.add(LSTM(64, dropout_U=0.1,dropout_W=0.1, return_sequences = False))\n",
        "# #model.add(LSTM(50, dropout_U=0.2,dropout_W=0.2, return_sequences = False))\n",
        "# model.add(Dense(1,activation='sigmoid'))\n",
        "# model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "# print(model.summary())\n",
        "\n",
        "# from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
        "# embed_dim = 150\n",
        "# lstm_out = 500\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(max_fatures, embed_dim,input_length = X1.shape[1], dropout=0.1))\n",
        "# model.add(Conv1D(64, 5, activation='relu')) # 128 * 128 5 FILTERS i/p - 10 filters +1 = 491\n",
        "# model.add(MaxPooling1D(pool_size=4)) # 4 LAYERS OF POOLING\n",
        "# model.add(Conv1D(64, 2, activation='relu'))\n",
        "# model.add(MaxPooling1D(pool_size=4))\n",
        "# model.add(LSTM(64, dropout_U=0.1,dropout_W=0.1, return_sequences = False))\n",
        "# model.add(Dense(1,activation='sigmoid'))\n",
        "# model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "# print(model.summary()) best 95.58\n",
        "\n",
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
        "embed_dim = 150\n",
        "lstm_out = 500\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_fatures, embed_dim,input_length = X1.shape[1], dropout=0.1))\n",
        "model.add(Conv1D(64, 5, activation='relu')) # 128 * 128 5 FILTERS i/p - 10 filters +1 = 491\n",
        "model.add(MaxPooling1D(pool_size=4)) # 4 LAYERS OF POOLING\n",
        "model.add(Conv1D(64, 2, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=4))\n",
        "model.add(LSTM(64,  return_sequences = False))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "EFcXlzrdYftG",
        "outputId": "828f13aa-3d55-45c6-ba82-c15d27614ac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unrecognized keyword arguments passed to Embedding: {'input_length': 1000, 'dropout': 0.1}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-80a4b040b4d1>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mlstm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_fatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 128 * 128 5 FILTERS i/p - 10 filters +1 = 491\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 4 LAYERS OF POOLING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dim, output_dim, embeddings_initializer, embeddings_regularizer, embeddings_constraint, mask_zero, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     ):\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_shape_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape_arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    265\u001b[0m                 \u001b[0;34m\"Unrecognized keyword arguments \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0;34mf\"passed to {self.__class__.__name__}: {kwargs}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized keyword arguments passed to Embedding: {'input_length': 1000, 'dropout': 0.1}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Embedding, LSTM, Conv1D, MaxPooling1D, Dropout\n",
        "from keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "max_features = 2000\n",
        "embed_dim = 150\n",
        "input_sequence_length = 1000  # Adjust this to the actual length of your input sequences\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_features, output_dim=embed_dim, input_shape=(input_sequence_length,)))\n",
        "model.add(Dropout(0.1))  # Add dropout after Embedding\n",
        "\n",
        "model.add(Conv1D(64, 5, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=4))\n",
        "\n",
        "model.add(Conv1D(64, 2, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=4))\n",
        "\n",
        "model.add(LSTM(64, dropout=0.1, recurrent_dropout=0.1, return_sequences=False))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "HbQg53wsgpNV",
        "outputId": "9d38fb12-bc75-4858-b11b-629c7b1df941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:69: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_13\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m    Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
              "│ embedding_12 (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m150\u001b[0m)             │     \u001b[38;5;34m300,000\u001b[0m │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m150\u001b[0m)             │           \u001b[38;5;34m0\u001b[0m │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m996\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │      \u001b[38;5;34m48,064\u001b[0m │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ max_pooling1d_6 (\u001b[38;5;33mMaxPooling1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m249\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │           \u001b[38;5;34m0\u001b[0m │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m248\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │       \u001b[38;5;34m8,256\u001b[0m │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ max_pooling1d_7 (\u001b[38;5;33mMaxPooling1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m0\u001b[0m │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                    │      \u001b[38;5;34m33,024\u001b[0m │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                     │          \u001b[38;5;34m65\u001b[0m │\n",
              "└────────────────────────────────────┴───────────────────────────────┴─────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                       </span>┃<span style=\"font-weight: bold\"> Output Shape                  </span>┃<span style=\"font-weight: bold\">     Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
              "│ embedding_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">300,000</span> │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">996</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │      <span style=\"color: #00af00; text-decoration-color: #00af00\">48,064</span> │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ max_pooling1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">249</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │       <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ max_pooling1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└────────────────────────────────────┴───────────────────────────────┴─────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m389,409\u001b[0m (1.49 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">389,409</span> (1.49 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m389,409\u001b[0m (1.49 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">389,409</span> (1.49 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "model.fit(X1_train,Y1_train,batch_size=35,epochs=15,verbose=1)\n",
        "print (time.time() - start_time, \"seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zglCD29cYuY1",
        "outputId": "55b70f6d-cf60-4a19-ed66-5db0dea17635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 393ms/step - accuracy: 0.5303 - loss: 0.6874\n",
            "Epoch 2/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 397ms/step - accuracy: 0.7584 - loss: 0.5113\n",
            "Epoch 3/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 415ms/step - accuracy: 0.8620 - loss: 0.3598\n",
            "Epoch 4/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 396ms/step - accuracy: 0.9116 - loss: 0.2309\n",
            "Epoch 5/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 390ms/step - accuracy: 0.9409 - loss: 0.1743\n",
            "Epoch 6/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 391ms/step - accuracy: 0.9617 - loss: 0.1163\n",
            "Epoch 7/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 394ms/step - accuracy: 0.9638 - loss: 0.0969\n",
            "Epoch 8/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 410ms/step - accuracy: 0.9636 - loss: 0.1036\n",
            "Epoch 9/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 403ms/step - accuracy: 0.9728 - loss: 0.0713\n",
            "Epoch 10/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 376ms/step - accuracy: 0.9770 - loss: 0.0596\n",
            "Epoch 11/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 390ms/step - accuracy: 0.9858 - loss: 0.0532\n",
            "Epoch 12/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 391ms/step - accuracy: 0.9774 - loss: 0.0611\n",
            "Epoch 13/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 384ms/step - accuracy: 0.9797 - loss: 0.0566\n",
            "Epoch 14/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 387ms/step - accuracy: 0.9804 - loss: 0.0579\n",
            "Epoch 15/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 398ms/step - accuracy: 0.9861 - loss: 0.0493\n",
            "589.6390998363495 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X1_test, Y1_test)\n",
        "#output: [loss, accuracy]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhCA4mUZZdmV",
        "outputId": "d7d36a03-50be-46f2-f85b-e5daac936c12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.8327 - loss: 0.7698\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8218148946762085, 0.8218606114387512]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, Masking, Embedding\n",
        "import re\n"
      ],
      "metadata": {
        "id": "CaMFfm_qb0kJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9in2EPH_b9cY",
        "outputId": "7d123738-a6ca-455a-8119-58e8232f04bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-utils\n",
            "  Using cached keras_utils-1.0.13-py3-none-any.whl\n",
            "Collecting Keras>=2.1.5 (from keras-utils)\n",
            "  Using cached keras-3.0.2-py3-none-any.whl (1.0 MB)\n",
            "Collecting absl-py (from Keras>=2.1.5->keras-utils)\n",
            "  Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "Collecting numpy (from Keras>=2.1.5->keras-utils)\n",
            "  Using cached numpy-1.26.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "Collecting rich (from Keras>=2.1.5->keras-utils)\n",
            "  Using cached rich-13.7.0-py3-none-any.whl (240 kB)\n",
            "Collecting namex (from Keras>=2.1.5->keras-utils)\n",
            "  Using cached namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
            "Collecting h5py (from Keras>=2.1.5->keras-utils)\n",
            "  Using cached h5py-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "Collecting dm-tree (from Keras>=2.1.5->keras-utils)\n",
            "  Using cached dm_tree-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->Keras>=2.1.5->keras-utils)\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich->Keras>=2.1.5->keras-utils)\n",
            "  Using cached pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->Keras>=2.1.5->keras-utils)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: namex, dm-tree, pygments, numpy, mdurl, absl-py, markdown-it-py, h5py, rich, Keras, keras-utils\n",
            "  Attempting uninstall: namex\n",
            "    Found existing installation: namex 0.0.7\n",
            "    Uninstalling namex-0.0.7:\n",
            "      Successfully uninstalled namex-0.0.7\n",
            "  Attempting uninstall: dm-tree\n",
            "    Found existing installation: dm-tree 0.1.8\n",
            "    Uninstalling dm-tree-0.1.8:\n",
            "      Successfully uninstalled dm-tree-0.1.8\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.17.2\n",
            "    Uninstalling Pygments-2.17.2:\n",
            "      Successfully uninstalled Pygments-2.17.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.3\n",
            "    Uninstalling numpy-1.26.3:\n",
            "      Successfully uninstalled numpy-1.26.3\n",
            "  Attempting uninstall: mdurl\n",
            "    Found existing installation: mdurl 0.1.2\n",
            "    Uninstalling mdurl-0.1.2:\n",
            "      Successfully uninstalled mdurl-0.1.2\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 2.1.0\n",
            "    Uninstalling absl-py-2.1.0:\n",
            "      Successfully uninstalled absl-py-2.1.0\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.10.0\n",
            "    Uninstalling h5py-3.10.0:\n",
            "      Successfully uninstalled h5py-3.10.0\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.7.0\n",
            "    Uninstalling rich-13.7.0:\n",
            "      Successfully uninstalled rich-13.7.0\n",
            "  Attempting uninstall: Keras\n",
            "    Found existing installation: keras 3.0.2\n",
            "    Uninstalling keras-3.0.2:\n",
            "      Successfully uninstalled keras-3.0.2\n",
            "  Attempting uninstall: keras-utils\n",
            "    Found existing installation: keras-utils 1.0.13\n",
            "    Uninstalling keras-utils-1.0.13:\n",
            "      Successfully uninstalled keras-utils-1.0.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.2 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires absl-py<2.0.0,>=0.9, but you have absl-py 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Keras-3.0.2 absl-py-2.1.0 dm-tree-0.1.8 h5py-3.10.0 keras-utils-1.0.13 markdown-it-py-3.0.0 mdurl-0.1.2 namex-0.0.7 numpy-1.26.3 pygments-2.17.2 rich-13.7.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "absl",
                  "h5py",
                  "keras",
                  "namex",
                  "tree"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Replace this import\n",
        "# from keras.utils import np_utils\n",
        "\n",
        "# With this import\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, Masking, Embedding\n",
        "import re\n"
      ],
      "metadata": {
        "id": "lzBu1-EClq7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 150\n",
        "lstm_out = 500\n",
        "rnn = Sequential()\n",
        "input_sequence_lenght = 1000\n",
        "rnn.add(Embedding(input_dim = max_fatures, output_dim = embed_dim,input_shape=(input_sequence_length,)))\n",
        "rnn.add(Dropout(0.1))\n",
        "rnn.add(LSTM(64,  return_sequences = True))\n",
        "rnn.add(LSTM(64,  return_sequences = False))\n",
        "\n",
        "\n",
        "\n",
        "#model.add(LSTM(50, dropout_U=0.2,dropout_W=0.2, return_sequences = False))\n",
        "rnn.add(Dense(1,activation='sigmoid'))\n",
        "rnn.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "print(rnn.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "CfF9QpormlUx",
        "outputId": "d84073f2-db77-4954-f574-d1f6108e5463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:69: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m    Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
              "│ embedding_15 (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m150\u001b[0m)             │     \u001b[38;5;34m300,000\u001b[0m │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m150\u001b[0m)             │           \u001b[38;5;34m0\u001b[0m │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │      \u001b[38;5;34m55,040\u001b[0m │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                    │      \u001b[38;5;34m33,024\u001b[0m │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                     │          \u001b[38;5;34m65\u001b[0m │\n",
              "└────────────────────────────────────┴───────────────────────────────┴─────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                       </span>┃<span style=\"font-weight: bold\"> Output Shape                  </span>┃<span style=\"font-weight: bold\">     Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
              "│ embedding_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">300,000</span> │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │      <span style=\"color: #00af00; text-decoration-color: #00af00\">55,040</span> │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└────────────────────────────────────┴───────────────────────────────┴─────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m388,129\u001b[0m (1.48 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">388,129</span> (1.48 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m388,129\u001b[0m (1.48 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">388,129</span> (1.48 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "rnn.fit(X1_train,Y1_train,batch_size=35,epochs=15,verbose=1)\n",
        "print (time.time() - start_time, \"seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQLmaucUnU1M",
        "outputId": "27d037fc-2739-48a3-a1de-81b74e5ff7d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 2s/step - accuracy: 0.5710 - loss: 0.6643\n",
            "Epoch 2/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 1s/step - accuracy: 0.7395 - loss: 0.5244\n",
            "Epoch 3/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 1s/step - accuracy: 0.8106 - loss: 0.4313\n",
            "Epoch 4/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 1s/step - accuracy: 0.8426 - loss: 0.3742\n",
            "Epoch 5/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 1s/step - accuracy: 0.8709 - loss: 0.3303\n",
            "Epoch 6/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 1s/step - accuracy: 0.8889 - loss: 0.2932\n",
            "Epoch 7/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 1s/step - accuracy: 0.8943 - loss: 0.2635\n",
            "Epoch 8/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 2s/step - accuracy: 0.9074 - loss: 0.2293\n",
            "Epoch 9/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 1s/step - accuracy: 0.9154 - loss: 0.2137\n",
            "Epoch 10/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 1s/step - accuracy: 0.9408 - loss: 0.1756\n",
            "Epoch 11/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 1s/step - accuracy: 0.9476 - loss: 0.1524\n",
            "Epoch 12/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 1s/step - accuracy: 0.9558 - loss: 0.1195\n",
            "Epoch 13/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 1s/step - accuracy: 0.9619 - loss: 0.1085\n",
            "Epoch 14/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 2s/step - accuracy: 0.9635 - loss: 0.1140\n",
            "Epoch 15/15\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 1s/step - accuracy: 0.9643 - loss: 0.1006\n",
            "2130.2610692977905 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn.evaluate(X1_test, Y1_test)\n",
        "#output: [loss, accuracy]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HealzaUmndaG",
        "outputId": "d6230a7b-7cdb-40d4-aac8-2616d084c66a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 307ms/step - accuracy: 0.8157 - loss: 0.7893\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8081098794937134, 0.8122119903564453]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MLP"
      ],
      "metadata": {
        "id": "35Ht29zInjiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vehryKyGw-jO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vectorizer = TfidfVectorizer(stop_words = stop_words, max_features = 500, ngram_range=(1,3), lowercase= True)\n",
        "tfdf = vectorizer.fit_transform(df_bjp.commentText)\n",
        "words = vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "C1Mvs54gnki_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "y= df_bjp.Label\n",
        "X_train, X_test, y_train, y_test = train_test_split( tfdf, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Md_RXhqMnpZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "mlp = Sequential()\n",
        "mlp.add(Dense(500, input_dim=500, activation='relu'))\n",
        "mlp.add(Dropout(0.1))\n",
        "mlp.add(Dense(550, activation='relu'))\n",
        "mlp.add(Dropout(0.1))\n",
        "\n",
        "mlp.add(Dense(100, activation='relu'))\n",
        "mlp.add(Dropout(0.1))\n",
        "\n",
        "mlp.add(Dense(10, activation='relu'))\n",
        "mlp.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "mlp.add(Dense(1, activation='sigmoid'))\n",
        "#best2937 hiddden 200 1\n",
        "# 82.10 500 550 500 5000 10\n",
        "# Compile model\n",
        "from keras import optimizers\n",
        "opt =optimizers.Adamax(learning_rate=0.001)\n",
        "mlp.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "mlp.fit(X_train, y_train, epochs=50, batch_size=150 )\n",
        "\n",
        "print (time.time() - start_time, \"seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "APBMtyIgnqQQ",
        "outputId": "ce3283a8-9601-4911-e7fd-ffbf734b27e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unrecognized data type: x=  (0, 95)\t0.39673702190689436\n  (0, 81)\t0.44927554558435373\n  (0, 477)\t0.40138745922592844\n  (0, 478)\t0.3472339641915974\n  (0, 80)\t0.4174135278740931\n  (0, 6)\t0.2797881475466874\n  (0, 475)\t0.2797881475466874\n  (0, 92)\t0.11557656559619511\n  (0, 51)\t0.1221191651369675\n  (1, 478)\t0.4312018899667154\n  (1, 270)\t0.46684710746936836\n  (1, 6)\t0.3474463631266439\n  (1, 2)\t0.3805947201545428\n  (1, 57)\t0.4478673843478993\n  (1, 269)\t0.19486242206432933\n  (1, 51)\t0.3032999086412069\n  (2, 145)\t0.7807843680169119\n  (2, 110)\t0.4427228815227016\n  (2, 372)\t0.3721789730857601\n  (2, 92)\t0.23633669378557484\n  (3, 97)\t0.597871705329582\n  (3, 239)\t0.6627305776121563\n  (3, 168)\t0.41944375608384005\n  (3, 92)\t0.16554316943454814\n  (4, 130)\t0.1671250432963843\n  :\t:\n  (3156, 188)\t0.06179749233478491\n  (3156, 51)\t0.027863247637931937\n  (3157, 60)\t0.4626953070663773\n  (3157, 59)\t0.4487460588814365\n  (3157, 165)\t0.41208752360985046\n  (3157, 31)\t0.3634268314946011\n  (3157, 164)\t0.3624467953271702\n  (3157, 142)\t0.36960050153610197\n  (3157, 51)\t0.12113062500190155\n  (3158, 101)\t0.3587365654791159\n  (3158, 204)\t0.5046856104928774\n  (3158, 270)\t0.4587975912461315\n  (3158, 6)\t0.3414555899335679\n  (3158, 2)\t0.3740323931628021\n  (3158, 203)\t0.3050322199632416\n  (3158, 92)\t0.14105052245488428\n  (3158, 269)\t0.19150254641637113\n  (3159, 107)\t0.3889352212574949\n  (3159, 141)\t0.4356937934472723\n  (3159, 435)\t0.30157231930011824\n  (3159, 312)\t0.44928755954648153\n  (3159, 402)\t0.37455156824045954\n  (3159, 311)\t0.32129636600396305\n  (3159, 254)\t0.3286660064388777\n  (3159, 92)\t0.12063814164020802 (of type <class 'scipy.sparse._csr.csr_matrix'>)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-eaf084911a26>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/__init__.py\u001b[0m in \u001b[0;36mget_data_adapter\u001b[0;34m(x, y, sample_weight, batch_size, steps_per_epoch, shuffle, class_weight)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unrecognized data type: x={x} (of type {type(x)})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized data type: x=  (0, 95)\t0.39673702190689436\n  (0, 81)\t0.44927554558435373\n  (0, 477)\t0.40138745922592844\n  (0, 478)\t0.3472339641915974\n  (0, 80)\t0.4174135278740931\n  (0, 6)\t0.2797881475466874\n  (0, 475)\t0.2797881475466874\n  (0, 92)\t0.11557656559619511\n  (0, 51)\t0.1221191651369675\n  (1, 478)\t0.4312018899667154\n  (1, 270)\t0.46684710746936836\n  (1, 6)\t0.3474463631266439\n  (1, 2)\t0.3805947201545428\n  (1, 57)\t0.4478673843478993\n  (1, 269)\t0.19486242206432933\n  (1, 51)\t0.3032999086412069\n  (2, 145)\t0.7807843680169119\n  (2, 110)\t0.4427228815227016\n  (2, 372)\t0.3721789730857601\n  (2, 92)\t0.23633669378557484\n  (3, 97)\t0.597871705329582\n  (3, 239)\t0.6627305776121563\n  (3, 168)\t0.41944375608384005\n  (3, 92)\t0.16554316943454814\n  (4, 130)\t0.1671250432963843\n  :\t:\n  (3156, 188)\t0.06179749233478491\n  (3156, 51)\t0.027863247637931937\n  (3157, 60)\t0.4626953070663773\n  (3157, 59)\t0.4487460588814365\n  (3157, 165)\t0.41208752360985046\n  (3157, 31)\t0.3634268314946011\n  (3157, 164)\t0.3624467953271702\n  (3157, 142)\t0.36960050153610197\n  (3157, 51)\t0.12113062500190155\n  (3158, 101)\t0.3587365654791159\n  (3158, 204)\t0.5046856104928774\n  (3158, 270)\t0.4587975912461315\n  (3158, 6)\t0.3414555899335679\n  (3158, 2)\t0.3740323931628021\n  (3158, 203)\t0.3050322199632416\n  (3158, 92)\t0.14105052245488428\n  (3158, 269)\t0.19150254641637113\n  (3159, 107)\t0.3889352212574949\n  (3159, 141)\t0.4356937934472723\n  (3159, 435)\t0.30157231930011824\n  (3159, 312)\t0.44928755954648153\n  (3159, 402)\t0.37455156824045954\n  (3159, 311)\t0.32129636600396305\n  (3159, 254)\t0.3286660064388777\n  (3159, 92)\t0.12063814164020802 (of type <class 'scipy.sparse._csr.csr_matrix'>)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mlp.evaluate(X_test, y_test))\n",
        "##output: [loss, accuracy]\n",
        "\n",
        "# from sklearn.metrics import precision_recall_curve\n",
        "# precision, recall, thresholds = precision_recall_curve(Y1_test, model.predict(X1_test))\n",
        "from sklearn.metrics import roc_curve\n",
        "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, mlp.predict(X_test))\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, auc\n",
        "from matplotlib import pyplot\n",
        "\n",
        "print(\"AUC: \"+ str(auc(fpr_keras, tpr_keras)))\n",
        "\n",
        "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
        "# plot the roc curve for the model\n",
        "pyplot.plot(fpr_keras, tpr_keras, marker='.')\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M01S_bwHnzpR",
        "outputId": "dc18e28a-21c1-4138-8183-85da98b6c5f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unrecognized data type: x=  (0, 107)\t0.4974899166393978\n  (0, 312)\t0.5746870386879119\n  (0, 402)\t0.479091679736915\n  (0, 311)\t0.4109725568773564\n  (0, 92)\t0.15430913876628605\n  (1, 431)\t0.8756715703493058\n  (1, 372)\t0.40766024100602183\n  (1, 92)\t0.25886758929014864\n  (2, 343)\t0.17596542319497926\n  (2, 347)\t0.1631385581421004\n  (2, 170)\t0.158725252651275\n  (2, 138)\t0.17033364380438015\n  (2, 38)\t0.1623541305718627\n  (2, 349)\t0.1272721857475122\n  (2, 45)\t0.14250945482120506\n  (2, 204)\t0.1608469502058136\n  (2, 479)\t0.12466768054055888\n  (2, 36)\t0.1193787772875472\n  (2, 314)\t0.10967181936746283\n  (2, 322)\t0.15048896805372253\n  (2, 408)\t0.3295499859456178\n  (2, 196)\t0.12843144594408165\n  (2, 202)\t0.1353573891749741\n  (2, 413)\t0.1785699284019326\n  (2, 83)\t0.11990091605049687\n  :\t:\n  (786, 58)\t0.5355495025903416\n  (786, 13)\t0.49148207118129095\n  (786, 212)\t0.24179392782713163\n  (786, 92)\t0.148286933898349\n  (786, 41)\t0.31507965395275234\n  (786, 51)\t0.15668121366104354\n  (787, 172)\t0.4374119293015772\n  (787, 69)\t0.5054211103281119\n  (787, 277)\t0.4415489103336676\n  (787, 233)\t0.40423456494670773\n  (787, 64)\t0.3316355941852513\n  (787, 269)\t0.22990214378499016\n  (787, 51)\t0.17891930744703977\n  (788, 331)\t0.5027219144284071\n  (788, 330)\t0.4301934631555592\n  (788, 69)\t0.39113617569978903\n  (788, 277)\t0.34170664549449037\n  (788, 233)\t0.312829754412672\n  (788, 329)\t0.27910034259865246\n  (788, 64)\t0.2566467355337365\n  (788, 269)\t0.1779170744309975\n  (788, 51)\t0.1384623875885571\n  (789, 354)\t0.8946883305161585\n  (789, 269)\t0.352517305826055\n  (789, 51)\t0.27434347145749377 (of type <class 'scipy.sparse._csr.csr_matrix'>)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-603a2031ca26>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m##output: [loss, accuracy]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# from sklearn.metrics import precision_recall_curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# precision, recall, thresholds = precision_recall_curve(Y1_test, model.predict(X1_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/__init__.py\u001b[0m in \u001b[0;36mget_data_adapter\u001b[0;34m(x, y, sample_weight, batch_size, steps_per_epoch, shuffle, class_weight)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unrecognized data type: x={x} (of type {type(x)})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized data type: x=  (0, 107)\t0.4974899166393978\n  (0, 312)\t0.5746870386879119\n  (0, 402)\t0.479091679736915\n  (0, 311)\t0.4109725568773564\n  (0, 92)\t0.15430913876628605\n  (1, 431)\t0.8756715703493058\n  (1, 372)\t0.40766024100602183\n  (1, 92)\t0.25886758929014864\n  (2, 343)\t0.17596542319497926\n  (2, 347)\t0.1631385581421004\n  (2, 170)\t0.158725252651275\n  (2, 138)\t0.17033364380438015\n  (2, 38)\t0.1623541305718627\n  (2, 349)\t0.1272721857475122\n  (2, 45)\t0.14250945482120506\n  (2, 204)\t0.1608469502058136\n  (2, 479)\t0.12466768054055888\n  (2, 36)\t0.1193787772875472\n  (2, 314)\t0.10967181936746283\n  (2, 322)\t0.15048896805372253\n  (2, 408)\t0.3295499859456178\n  (2, 196)\t0.12843144594408165\n  (2, 202)\t0.1353573891749741\n  (2, 413)\t0.1785699284019326\n  (2, 83)\t0.11990091605049687\n  :\t:\n  (786, 58)\t0.5355495025903416\n  (786, 13)\t0.49148207118129095\n  (786, 212)\t0.24179392782713163\n  (786, 92)\t0.148286933898349\n  (786, 41)\t0.31507965395275234\n  (786, 51)\t0.15668121366104354\n  (787, 172)\t0.4374119293015772\n  (787, 69)\t0.5054211103281119\n  (787, 277)\t0.4415489103336676\n  (787, 233)\t0.40423456494670773\n  (787, 64)\t0.3316355941852513\n  (787, 269)\t0.22990214378499016\n  (787, 51)\t0.17891930744703977\n  (788, 331)\t0.5027219144284071\n  (788, 330)\t0.4301934631555592\n  (788, 69)\t0.39113617569978903\n  (788, 277)\t0.34170664549449037\n  (788, 233)\t0.312829754412672\n  (788, 329)\t0.27910034259865246\n  (788, 64)\t0.2566467355337365\n  (788, 269)\t0.1779170744309975\n  (788, 51)\t0.1384623875885571\n  (789, 354)\t0.8946883305161585\n  (789, 269)\t0.352517305826055\n  (789, 51)\t0.27434347145749377 (of type <class 'scipy.sparse._csr.csr_matrix'>)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "mlp = Sequential()\n",
        "mlp.add(Dense(500, input_dim=500, activation='relu'))\n",
        "mlp.add(Dropout(0.1))\n",
        "mlp.add(Dense(550, activation='relu'))\n",
        "mlp.add(Dropout(0.1))\n",
        "\n",
        "mlp.add(Dense(100, activation='relu'))\n",
        "mlp.add(Dropout(0.1))\n",
        "\n",
        "mlp.add(Dense(10, activation='relu'))\n",
        "mlp.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "mlp.add(Dense(1, activation='sigmoid'))\n",
        "#best2937 hiddden 200 1\n",
        "# 82.10 500 550 500 5000 10\n",
        "# Compile model\n",
        "from keras import optimizers\n",
        "opt =optimizers.Adamax(learning_rate=0.001)\n",
        "mlp.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "mlp.fit(X_train.todense(), y_train, epochs=50, batch_size=150 )\n",
        "\n",
        "print (time.time() - start_time, \"seconds\")\n",
        "\n",
        "print(mlp.evaluate(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CAvqyEOqz4mi",
        "outputId": "09e6cef3-2a92-4b4f-f3e5-fcc216debfd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.6442 - loss: 0.6750\n",
            "Epoch 2/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7480 - loss: 0.5719\n",
            "Epoch 3/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7850 - loss: 0.4797\n",
            "Epoch 4/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8298 - loss: 0.4175\n",
            "Epoch 5/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8379 - loss: 0.3868\n",
            "Epoch 6/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8572 - loss: 0.3562\n",
            "Epoch 7/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8630 - loss: 0.3532\n",
            "Epoch 8/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8812 - loss: 0.3118\n",
            "Epoch 9/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8956 - loss: 0.2815\n",
            "Epoch 10/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9020 - loss: 0.2723\n",
            "Epoch 11/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9070 - loss: 0.2543\n",
            "Epoch 12/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9222 - loss: 0.2320\n",
            "Epoch 13/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9233 - loss: 0.2151\n",
            "Epoch 14/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9223 - loss: 0.2180\n",
            "Epoch 15/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9415 - loss: 0.1827\n",
            "Epoch 16/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9403 - loss: 0.1813\n",
            "Epoch 17/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9422 - loss: 0.1682\n",
            "Epoch 18/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9498 - loss: 0.1608\n",
            "Epoch 19/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9472 - loss: 0.1519\n",
            "Epoch 20/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9502 - loss: 0.1414\n",
            "Epoch 21/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9587 - loss: 0.1321\n",
            "Epoch 22/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9528 - loss: 0.1349\n",
            "Epoch 23/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9572 - loss: 0.1366\n",
            "Epoch 24/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9611 - loss: 0.1205\n",
            "Epoch 25/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9515 - loss: 0.1257\n",
            "Epoch 26/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9655 - loss: 0.1088\n",
            "Epoch 27/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9599 - loss: 0.1131\n",
            "Epoch 28/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9633 - loss: 0.1057\n",
            "Epoch 29/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9532 - loss: 0.1141\n",
            "Epoch 30/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9613 - loss: 0.1066\n",
            "Epoch 31/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9652 - loss: 0.0934\n",
            "Epoch 32/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9671 - loss: 0.0874\n",
            "Epoch 33/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9563 - loss: 0.1085\n",
            "Epoch 34/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9661 - loss: 0.0952\n",
            "Epoch 35/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9674 - loss: 0.0939\n",
            "Epoch 36/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9627 - loss: 0.0954\n",
            "Epoch 37/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9669 - loss: 0.0915\n",
            "Epoch 38/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9643 - loss: 0.0876\n",
            "Epoch 39/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9653 - loss: 0.0824\n",
            "Epoch 40/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9655 - loss: 0.0928\n",
            "Epoch 41/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9726 - loss: 0.0791\n",
            "Epoch 42/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9648 - loss: 0.0876\n",
            "Epoch 43/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9613 - loss: 0.0913\n",
            "Epoch 44/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9700 - loss: 0.0753\n",
            "Epoch 45/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9638 - loss: 0.0784\n",
            "Epoch 46/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9670 - loss: 0.0830\n",
            "Epoch 47/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9631 - loss: 0.0829\n",
            "Epoch 48/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9658 - loss: 0.0822\n",
            "Epoch 49/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9647 - loss: 0.0909\n",
            "Epoch 50/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9609 - loss: 0.0871\n",
            "32.11539435386658 seconds\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unrecognized data type: x=  (0, 107)\t0.4974899166393978\n  (0, 312)\t0.5746870386879119\n  (0, 402)\t0.479091679736915\n  (0, 311)\t0.4109725568773564\n  (0, 92)\t0.15430913876628605\n  (1, 431)\t0.8756715703493058\n  (1, 372)\t0.40766024100602183\n  (1, 92)\t0.25886758929014864\n  (2, 343)\t0.17596542319497926\n  (2, 347)\t0.1631385581421004\n  (2, 170)\t0.158725252651275\n  (2, 138)\t0.17033364380438015\n  (2, 38)\t0.1623541305718627\n  (2, 349)\t0.1272721857475122\n  (2, 45)\t0.14250945482120506\n  (2, 204)\t0.1608469502058136\n  (2, 479)\t0.12466768054055888\n  (2, 36)\t0.1193787772875472\n  (2, 314)\t0.10967181936746283\n  (2, 322)\t0.15048896805372253\n  (2, 408)\t0.3295499859456178\n  (2, 196)\t0.12843144594408165\n  (2, 202)\t0.1353573891749741\n  (2, 413)\t0.1785699284019326\n  (2, 83)\t0.11990091605049687\n  :\t:\n  (786, 58)\t0.5355495025903416\n  (786, 13)\t0.49148207118129095\n  (786, 212)\t0.24179392782713163\n  (786, 92)\t0.148286933898349\n  (786, 41)\t0.31507965395275234\n  (786, 51)\t0.15668121366104354\n  (787, 172)\t0.4374119293015772\n  (787, 69)\t0.5054211103281119\n  (787, 277)\t0.4415489103336676\n  (787, 233)\t0.40423456494670773\n  (787, 64)\t0.3316355941852513\n  (787, 269)\t0.22990214378499016\n  (787, 51)\t0.17891930744703977\n  (788, 331)\t0.5027219144284071\n  (788, 330)\t0.4301934631555592\n  (788, 69)\t0.39113617569978903\n  (788, 277)\t0.34170664549449037\n  (788, 233)\t0.312829754412672\n  (788, 329)\t0.27910034259865246\n  (788, 64)\t0.2566467355337365\n  (788, 269)\t0.1779170744309975\n  (788, 51)\t0.1384623875885571\n  (789, 354)\t0.8946883305161585\n  (789, 269)\t0.352517305826055\n  (789, 51)\t0.27434347145749377 (of type <class 'scipy.sparse._csr.csr_matrix'>)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-395f06aad61e>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/__init__.py\u001b[0m in \u001b[0;36mget_data_adapter\u001b[0;34m(x, y, sample_weight, batch_size, steps_per_epoch, shuffle, class_weight)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unrecognized data type: x={x} (of type {type(x)})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized data type: x=  (0, 107)\t0.4974899166393978\n  (0, 312)\t0.5746870386879119\n  (0, 402)\t0.479091679736915\n  (0, 311)\t0.4109725568773564\n  (0, 92)\t0.15430913876628605\n  (1, 431)\t0.8756715703493058\n  (1, 372)\t0.40766024100602183\n  (1, 92)\t0.25886758929014864\n  (2, 343)\t0.17596542319497926\n  (2, 347)\t0.1631385581421004\n  (2, 170)\t0.158725252651275\n  (2, 138)\t0.17033364380438015\n  (2, 38)\t0.1623541305718627\n  (2, 349)\t0.1272721857475122\n  (2, 45)\t0.14250945482120506\n  (2, 204)\t0.1608469502058136\n  (2, 479)\t0.12466768054055888\n  (2, 36)\t0.1193787772875472\n  (2, 314)\t0.10967181936746283\n  (2, 322)\t0.15048896805372253\n  (2, 408)\t0.3295499859456178\n  (2, 196)\t0.12843144594408165\n  (2, 202)\t0.1353573891749741\n  (2, 413)\t0.1785699284019326\n  (2, 83)\t0.11990091605049687\n  :\t:\n  (786, 58)\t0.5355495025903416\n  (786, 13)\t0.49148207118129095\n  (786, 212)\t0.24179392782713163\n  (786, 92)\t0.148286933898349\n  (786, 41)\t0.31507965395275234\n  (786, 51)\t0.15668121366104354\n  (787, 172)\t0.4374119293015772\n  (787, 69)\t0.5054211103281119\n  (787, 277)\t0.4415489103336676\n  (787, 233)\t0.40423456494670773\n  (787, 64)\t0.3316355941852513\n  (787, 269)\t0.22990214378499016\n  (787, 51)\t0.17891930744703977\n  (788, 331)\t0.5027219144284071\n  (788, 330)\t0.4301934631555592\n  (788, 69)\t0.39113617569978903\n  (788, 277)\t0.34170664549449037\n  (788, 233)\t0.312829754412672\n  (788, 329)\t0.27910034259865246\n  (788, 64)\t0.2566467355337365\n  (788, 269)\t0.1779170744309975\n  (788, 51)\t0.1384623875885571\n  (789, 354)\t0.8946883305161585\n  (789, 269)\t0.352517305826055\n  (789, 51)\t0.27434347145749377 (of type <class 'scipy.sparse._csr.csr_matrix'>)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "mlp = Sequential()\n",
        "mlp.add(Dense(500, input_dim=500, activation='relu'))\n",
        "mlp.add(Dropout(0.1))\n",
        "mlp.add(Dense(550, activation='relu'))\n",
        "mlp.add(Dropout(0.1))\n",
        "\n",
        "mlp.add(Dense(100, activation='relu'))\n",
        "mlp.add(Dropout(0.1))\n",
        "\n",
        "mlp.add(Dense(10, activation='relu'))\n",
        "mlp.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "mlp.add(Dense(1, activation='sigmoid'))\n",
        "#best2937 hiddden 200 1\n",
        "# 82.10 500 550 500 5000 10\n",
        "# Compile model\n",
        "from keras import optimizers\n",
        "opt =optimizers.Adamax(learning_rate=0.001)\n",
        "mlp.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "mlp.fit(X_train.todense(), y_train, epochs=50, batch_size=150 )\n",
        "\n",
        "print (time.time() - start_time, \"seconds\")\n",
        "\n",
        "print(mlp.evaluate(X_test.todense(), y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNT1FiDR0QRj",
        "outputId": "140f4599-c683-4270-be4d-26b03613ed9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:73: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.5869 - loss: 0.6778\n",
            "Epoch 2/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7450 - loss: 0.5666\n",
            "Epoch 3/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7722 - loss: 0.4863\n",
            "Epoch 4/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8322 - loss: 0.4169\n",
            "Epoch 5/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8537 - loss: 0.3650\n",
            "Epoch 6/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8619 - loss: 0.3522\n",
            "Epoch 7/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8799 - loss: 0.3195\n",
            "Epoch 8/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8972 - loss: 0.2860\n",
            "Epoch 9/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8948 - loss: 0.2797\n",
            "Epoch 10/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9108 - loss: 0.2564\n",
            "Epoch 11/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9246 - loss: 0.2355\n",
            "Epoch 12/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9119 - loss: 0.2256\n",
            "Epoch 13/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9370 - loss: 0.1974\n",
            "Epoch 14/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9458 - loss: 0.1696\n",
            "Epoch 15/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9453 - loss: 0.1700\n",
            "Epoch 16/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9471 - loss: 0.1682\n",
            "Epoch 17/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9471 - loss: 0.1598\n",
            "Epoch 18/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9573 - loss: 0.1350\n",
            "Epoch 19/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9548 - loss: 0.1303\n",
            "Epoch 20/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9551 - loss: 0.1296\n",
            "Epoch 21/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9574 - loss: 0.1232\n",
            "Epoch 22/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9613 - loss: 0.1161\n",
            "Epoch 23/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9497 - loss: 0.1258\n",
            "Epoch 24/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9622 - loss: 0.1056\n",
            "Epoch 25/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9568 - loss: 0.1107\n",
            "Epoch 26/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9629 - loss: 0.0961\n",
            "Epoch 27/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9557 - loss: 0.1092\n",
            "Epoch 28/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9650 - loss: 0.0999\n",
            "Epoch 29/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9594 - loss: 0.1039\n",
            "Epoch 30/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9655 - loss: 0.0994\n",
            "Epoch 31/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9635 - loss: 0.0933\n",
            "Epoch 32/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9630 - loss: 0.0924\n",
            "Epoch 33/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9618 - loss: 0.0916\n",
            "Epoch 34/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9655 - loss: 0.0908\n",
            "Epoch 35/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9690 - loss: 0.0867\n",
            "Epoch 36/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9656 - loss: 0.0847\n",
            "Epoch 37/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9604 - loss: 0.0914\n",
            "Epoch 38/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9738 - loss: 0.0744\n",
            "Epoch 39/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9615 - loss: 0.0895\n",
            "Epoch 40/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9690 - loss: 0.0797\n",
            "Epoch 41/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9668 - loss: 0.0843\n",
            "Epoch 42/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9669 - loss: 0.0926\n",
            "Epoch 43/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9626 - loss: 0.0894\n",
            "Epoch 44/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9589 - loss: 0.0963\n",
            "Epoch 45/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9676 - loss: 0.0825\n",
            "Epoch 46/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9626 - loss: 0.0896\n",
            "Epoch 47/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9690 - loss: 0.0818\n",
            "Epoch 48/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9677 - loss: 0.0776\n",
            "Epoch 49/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9682 - loss: 0.0850\n",
            "Epoch 50/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9675 - loss: 0.0771\n",
            "31.341981887817383 seconds\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7934 - loss: 0.7317\n",
            "[0.7169593572616577, 0.798734188079834]\n"
          ]
        }
      ]
    }
  ]
}